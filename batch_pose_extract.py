import os
import csv
import json
import cv2
import numpy as np
import mediapipe as mp
import faulthandler

faulthandler.enable()


# ===============================
# æ ‡ç­¾è¯´æ˜ï¼ˆä½ äººå·¥æ ‡æ³¨ï¼‰
# ===============================
LABEL_MAP = {
    0: "è‡ªç„¶åï¼ˆä¸åˆ»æ„æ‘†ï¼‰",
    1: "èº«ä½“å‰å€¾+å¤´å‰ä¼¸ï¼ˆè´´å±å¹•çœ‹ï¼‰",
    2: "é æ¤…èƒŒ+è…°å¡Œ+è‚©å‘å",
    3: "èº«ä½“åä¸€ä¾§ï¼ˆå·¦å³å‡å¯ï¼‰"
}

# ===============================
# æ—‹è½¬è§’åº¦è¯´æ˜ï¼ˆé¡ºæ—¶é’ˆï¼‰
# 0/90/180/270
# ===============================
ROTATIONS = {
    0: None,
    90: cv2.ROTATE_90_CLOCKWISE,
    180: cv2.ROTATE_180,
    270: cv2.ROTATE_90_COUNTERCLOCKWISE,  # ç­‰ä»·äºé€†æ—¶é’ˆ 90
}


def rotate_frame(frame, deg_clockwise: int):
    code = ROTATIONS.get(deg_clockwise)
    if code is None:
        return frame
    return cv2.rotate(frame, code)


# ===============================
# ç¨³å®šå™¨ï¼švisibility é—¨æ§ + EMA å¹³æ»‘
# ===============================
class LandmarkStabilizer:
    """
    cur: (33,4) -> [x,y,z,vis]  (x,yå½’ä¸€åŒ–ï¼Œzç›¸å¯¹)
    è§„åˆ™ï¼š
      - vis < vis_th: ä¸æ›´æ–°ï¼ˆæ²¿ç”¨ä¸Šä¸€å¸§ï¼‰
      - vis >= vis_th: ç”¨ EMA å¹³æ»‘æ›´æ–°
    """
    def __init__(self, alpha=0.2, vis_th=0.5):
        self.alpha = float(alpha)     # è¶Šå°è¶Šç¨³(æ›´æ…¢)ï¼Œè¶Šå¤§è¶Šè·Ÿæ‰‹(æ›´æŠ–)
        self.vis_th = float(vis_th)   # è¶Šé«˜è¶Šä¸¥æ ¼(æ›´å¤šç‚¹å†»ç»“)
        self.prev = None              # (33,4)

    def update(self, cur: np.ndarray) -> np.ndarray:
        if self.prev is None:
            self.prev = cur.copy()
            return cur

        out = self.prev.copy()
        vis = cur[:, 3]
        good = vis >= self.vis_th

        # EMA å¹³æ»‘å¯é ç‚¹
        out[good, :3] = (1.0 - self.alpha) * self.prev[good, :3] + self.alpha * cur[good, :3]
        out[good, 3] = cur[good, 3]

        self.prev = out
        return out


# ===============================
# ä¸»å¤„ç†å‡½æ•°ï¼šå•è§†é¢‘ç¦»çº¿å¤„ç†
# ===============================
def process_single_video(
    video_path: str,
    label: int,
    rotation_deg: int,
    out_dir: str = "recording_test",
    merged_csv: str = "recording_test/all_landmarks.csv",
    # ç¨³å®šç›¸å…³å‚æ•°
    model_complexity: int = 2,
    min_det: float = 0.7,
    min_track: float = 0.7,
    ema_alpha: float = 0.2,
    vis_th: float = 0.5,
    # é¢å¤–è¾“å‡º
    save_world_landmarks: bool = True,  # CSV é‡Œé¢å¤–å†™ world_x/y/zï¼ˆæ›´é€‚åˆDLï¼‰
    fill_missing_with_prev: bool = True # æ²¡æ£€æµ‹åˆ°äººä½“æ—¶ï¼šç”¨ä¸Šä¸€å¸§ï¼ˆæ›´ç¨³ï¼‰ï¼Œå¦åˆ™å†™0
):
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶: {video_path}")

    if label not in LABEL_MAP:
        raise ValueError("âŒ label å¿…é¡»æ˜¯ 0/1/2/3")

    if rotation_deg not in ROTATIONS:
        raise ValueError("âŒ rotation_deg å¿…é¡»æ˜¯ 0/90/180/270ï¼ˆé¡ºæ—¶é’ˆï¼‰")

    os.makedirs(out_dir, exist_ok=True)

    video_name = os.path.basename(video_path)
    base = os.path.splitext(video_name)[0]

    out_video_path = os.path.join(out_dir, f"{base}_pose_fix.mp4")
    meta_path = os.path.join(out_dir, f"{base}_meta.json")

    print("\n==============================")
    print("ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘:", video_name)
    print("æ ‡ç­¾:", label, "-", LABEL_MAP[label])
    print("æ—‹è½¬ä¿®æ­£: é¡ºæ—¶é’ˆ", rotation_deg, "åº¦")
    print("ç¨³å®šå‚æ•°: model_complexity=", model_complexity,
          "min_det=", min_det, "min_track=", min_track,
          "ema_alpha=", ema_alpha, "vis_th=", vis_th)
    print("==============================\n")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError("âŒ æ— æ³•æ‰“å¼€è§†é¢‘")

    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps is None or fps <= 1:
        fps = 30.0

    # è¯»ç¬¬ä¸€å¸§ï¼Œç¡®å®šæ—‹è½¬åçš„å°ºå¯¸
    ret, first = cap.read()
    if not ret:
        raise RuntimeError("âŒ è§†é¢‘ä¸ºç©º")

    first = rotate_frame(first, rotation_deg)
    h, w = first.shape[:2]

    # writer è¾“å‡ºâ€œæ—‹è½¬ä¿®æ­£ + æ ‡è®°éª¨æ¶â€çš„ mp4
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    writer = cv2.VideoWriter(out_video_path, fourcc, fps, (w, h))
    if not writer.isOpened():
        raise RuntimeError("âŒ è¾“å‡º mp4 writer æ‰“å¼€å¤±è´¥ï¼ˆå¯å°è¯• XVID + .aviï¼‰")

    # ç»Ÿä¸€ CSV æ±‡æ€»ï¼ˆè¿½åŠ å†™å…¥ï¼‰
    csv_exists = os.path.exists(merged_csv)
    csv_f = open(merged_csv, "a", newline="", encoding="utf-8")
    csv_writer = csv.writer(csv_f)

    # è¡¨å¤´ï¼šåŒ…å« image-space landmarks + å¯é€‰ world-space
    if not csv_exists:
        header = [
            "video", "label", "frame", "timestamp_ms",
            "rotation_deg_clockwise", "landmark_id",
            "x", "y", "z", "visibility"
        ]
        if save_world_landmarks:
            header += ["world_x", "world_y", "world_z"]
        csv_writer.writerow(header)

    # åˆå§‹åŒ– Pose
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils
    pose = mp_pose.Pose(
        static_image_mode=False,
        model_complexity=int(model_complexity),
        smooth_landmarks=False,
        min_detection_confidence=float(min_det),
        min_tracking_confidence=float(min_track),
    )

    stabilizer = LandmarkStabilizer(alpha=ema_alpha, vis_th=vis_th)

    # å›åˆ°è§†é¢‘å¼€å¤´
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

    # ===============================
    # è¿›åº¦ï¼šå°è¯•è¯»å–æ€»å¸§æ•°ï¼ˆæœ‰äº›è§†é¢‘/è§£ç å™¨å¯èƒ½è¿”å› 0ï¼‰
    # ===============================
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)

    frame_idx = 0
    missing_frames = 0
    last_good = None  # (33,4) æœ€åä¸€æ¬¡ç¨³å®šåçš„ç‚¹

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        t_ms = cap.get(cv2.CAP_PROP_POS_MSEC)

        frame = rotate_frame(frame, rotation_deg)

        # ===============================
        # âœ… å…³é”®ä¿®å¤ï¼šä¿è¯è¾“å…¥ç»™ mediapipe çš„å›¾åƒæ˜¯è¿ç»­å†…å­˜ + uint8
        # ===============================
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        rgb = np.ascontiguousarray(rgb, dtype=np.uint8)

        # ï¼ˆå¯é€‰å¿ƒè·³å®šä½ï¼šå¦‚æœè¿˜å´©ï¼Œå¯ä»¥æ‰“å¼€ï¼‰
        # if frame_idx % 50 == 0:
        #     print(f"[hb] before pose.process frame={frame_idx}")

        results = pose.process(rgb)

        # if frame_idx % 50 == 0:
        #     print(f"[hb] after  pose.process frame={frame_idx}")

        # ===============================
        # è¿›åº¦ï¼šæ¯å¤„ç† 500 å¸§æ‰“å°ä¸€æ¬¡
        # ===============================
        if frame_idx > 0 and frame_idx % 500 == 0:
            if total_frames > 0:
                pct = 100.0 * frame_idx / total_frames
                print(f"[è¿›åº¦] {frame_idx}/{total_frames} å¸§ ({pct:.2f}%)ï¼Œmissing={missing_frames}")
            else:
                print(f"[è¿›åº¦] å·²å¤„ç† {frame_idx} å¸§ï¼Œmissing={missing_frames}")

        if results.pose_landmarks:
            lm = results.pose_landmarks.landmark
            cur = np.array([[p.x, p.y, p.z, p.visibility] for p in lm], dtype=np.float32)
            cur = stabilizer.update(cur)
            last_good = cur

            # world landmarksï¼ˆæ›´é€‚åˆDLï¼Œè§†è§’å˜åŒ–æ›´é²æ£’ï¼‰
            world = None
            if save_world_landmarks and results.pose_world_landmarks:
                wlm = results.pose_world_landmarks.landmark
                world = np.array([[p.x, p.y, p.z] for p in wlm], dtype=np.float32)  # (33,3)

            # å†™ CSVï¼šæ¯å¸§33è¡Œ
            for i in range(33):
                row = [
                    video_name, label, frame_idx, float(t_ms),
                    rotation_deg, i,
                    float(cur[i, 0]), float(cur[i, 1]), float(cur[i, 2]), float(cur[i, 3])
                ]
                if save_world_landmarks:
                    if world is None:
                        row += ["", "", ""]
                    else:
                        row += [float(world[i, 0]), float(world[i, 1]), float(world[i, 2])]
                csv_writer.writerow(row)

            # å¯è§†åŒ–ï¼šç”¨åŸ results ç”»éª¨æ¶ï¼ˆç”»å›¾ç”¨ results çš„ landmarksï¼Œç¨³å®šåçš„ä¸»è¦ç”¨äºè®­ç»ƒæ•°æ®ï¼‰
            vis = frame.copy()
            mp_drawing.draw_landmarks(vis, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            cv2.putText(
                vis,
                f"label={label} rot={rotation_deg} vis_th={vis_th} alpha={ema_alpha}",
                (20, 40),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 255, 0),
                2
            )
            writer.write(vis)

        else:
            missing_frames += 1

            # æ²¡æ£€æµ‹åˆ°ï¼šæ›´ç¨³çš„åšæ³•æ˜¯æ²¿ç”¨ä¸Šä¸€å¸§
            if fill_missing_with_prev and last_good is not None:
                cur = last_good
            else:
                cur = np.zeros((33, 4), dtype=np.float32)

            for i in range(33):
                row = [
                    video_name, label, frame_idx, float(t_ms),
                    rotation_deg, i,
                    float(cur[i, 0]), float(cur[i, 1]), float(cur[i, 2]), float(cur[i, 3])
                ]
                if save_world_landmarks:
                    row += ["", "", ""]
                csv_writer.writerow(row)

            writer.write(frame)

        frame_idx += 1

    cap.release()
    writer.release()
    pose.close()
    csv_f.close()

    meta = {
        "video": video_path,
        "label": label,
        "label_name": LABEL_MAP[label],
        "rotation_deg_clockwise": rotation_deg,
        "fps": float(fps),
        "frames_processed": int(frame_idx),
        "missing_frames": int(missing_frames),
        "stabilizer": {
            "ema_alpha": float(ema_alpha),
            "visibility_threshold": float(vis_th),
            "fill_missing_with_prev": bool(fill_missing_with_prev),
        },
        "pose_model": {
            "model_complexity": int(model_complexity),
            "min_detection_confidence": float(min_det),
            "min_tracking_confidence": float(min_track),
            "save_world_landmarks": bool(save_world_landmarks),
        },
        "outputs": {
            "merged_csv": os.path.abspath(merged_csv),
            "marked_video": os.path.abspath(out_video_path),
        }
    }

    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)

    print("âœ… å®Œæˆï¼")
    print("CSVï¼ˆè¿½åŠ æ±‡æ€»ï¼‰:", os.path.abspath(merged_csv))
    print("æ ‡è®°è§†é¢‘è¾“å‡º:", os.path.abspath(out_video_path))
    print("Meta è¾“å‡º:", os.path.abspath(meta_path))


# ===============================
# æ¯æ¬¡ä¸€ä¸ªè§†é¢‘ï¼šåªæ”¹è¿™é‡Œ
# ===============================
if __name__ == "__main__":
    # è¾“å…¥è§†é¢‘
    video_path = r"D:\MediaPipe Pose pose_estimation\recordings\07.MP4"

    # æ ‡ç­¾ï¼ˆæ¯ä¸ªè§†é¢‘ä¸€ç§å§¿åŠ¿ï¼‰
    # 0 è‡ªç„¶å
    # 1 èº«ä½“å‰å€¾+å¤´å‰ä¼¸
    # 2 é æ¤…èƒŒ+è…°å¡Œ+è‚©å‘å
    # 3 èº«ä½“åä¸€ä¾§
    label = 0

    # æ—‹è½¬ä¿®æ­£è§’åº¦ï¼ˆé¡ºæ—¶é’ˆï¼‰ï¼š0/90/180/270
    rotation_deg = 0

    # ç¨³å®šå‚æ•°ï¼ˆæ–œåæ–¹å»ºè®®æ›´ç¨³ä¸€ç‚¹ï¼‰
    process_single_video(
        video_path=video_path,
        label=label,
        rotation_deg=rotation_deg,
        out_dir="recording_test",
        merged_csv="recording_test/all_landmarks.csv",
        model_complexity=1,
        min_det=0.7,
        min_track=0.7,
        ema_alpha=0.25,   # æ›´ç¨³ï¼š0.10~0.25å¯è°ƒ
        vis_th=0.70,      # æ›´ä¸¥æ ¼ï¼š0.45~0.70å¯è°ƒ
        save_world_landmarks=True,
        fill_missing_with_prev=True
    )
